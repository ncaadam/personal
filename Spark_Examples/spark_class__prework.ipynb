{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apache Spark Class: Pre-work\n",
    "In this section we cover the following:\n",
    "1. Prerequisites\n",
    "2. Downloading and building Spark\n",
    "3. Configuring environment variables\n",
    "4. Using pyspark\n",
    "5. Using pyspark in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "<b>In order to start this class you will have to have the following environment working and configured:</b>\n",
    "* Ubuntu 14.04 LTS (either native or running in a virutal environment)\n",
    "* Python package manager Anaconda\n",
    "* For more information on setting this up, see the following document: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:red\">This process takes a while to figure out, please do this well in advance of starting the class!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to have some familiarity with working with:<br>\n",
    "* A linux command line environment: http://www.ee.surrey.ac.uk/Teaching/Unix/\n",
    "* Python development: http://www.learnpython.org/\n",
    "* MapReduce concepts: http://en.wikipedia.org/wiki/MapReduce\n",
    "* Lambda architecture: http://en.wikipedia.org/wiki/Lambda_architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Installing Build Essentials, Java, Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point forward, we are assuming you have Ubuntu open and Anaconda installed.  If you don't, see above and get it fixed.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Build Essentials\n",
    "To install the build essentials, open up the terminal in Ubuntu and do the following:\n",
    "```\n",
    "$ sudo apt-get install build-essential checkinstall\n",
    "```\n",
    "\n",
    "Follow the prompts and install the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Java\n",
    "To get Java, open up the terminal in Ubuntu and do the following:\n",
    "```\n",
    "$ sudo apt-add-repository ppa:webupd8team/java\n",
    "$ sudo apt-get update\n",
    "$ sudo apt-get install oracle-java7-installer\n",
    "```\n",
    "\n",
    "You can check that it is successful by running:\n",
    "\n",
    "```\n",
    "$ java -version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Spark\n",
    "* To download Spark, open up a browser in Ubuntu and go to the download page: https://spark.apache.org/downloads.html\n",
    "* Accept the default dropdowns and click \"Download Spark: spark-1.3.0.tgz\" (the latest as of when this was written). Select a mirror and download.\n",
    "\n",
    "To build Spark, we need to move it to a permanent directory, build it, set SPARK_HOME and add it to the python path:\n",
    "```\n",
    "$ cd ~/Downloads\n",
    "$ mkdir ~/spark\n",
    "$ mv ~/Downloads/spark-1.3.0.tgz ~/spark/spark-1.3.0.tgz\n",
    "$ cd ~/spark\n",
    "$ tar -xvzf spark-1.3.0.tgz\n",
    "$ cd spark-1.3.0\n",
    "$ build/sbt -Pyarn -Phadoop-2.3 assembly\n",
    "```\n",
    "\n",
    "You can then wait for it to build; do this on a fast internet connection.  It should take about 20 mintues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tell python where Spark is located, we will have to add SPARK_HOME to the Python path:\n",
    "```\n",
    "$ sudo nano ~/.bashrc\n",
    "```\n",
    "\n",
    "add the following lines: \n",
    "```\n",
    "export SPARK_HOME=/home/<YOUR USERNAME>/spark/spark-1.3.0\n",
    "export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH\n",
    "```\n",
    "\n",
    "CTRL-X to save and exit, then:\n",
    "```\n",
    "$ source ~/.bashrc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Using pyspark\n",
    "You can check if it worked by opening pyspark\n",
    "```\n",
    "$ ./bin/pyspark\n",
    ">>> print sc\n",
    "<pyspark.context.SparkContext object at 0x7fe62e2f3090>\n",
    "```\n",
    "CTRL+D to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Using pyspark in Jupyter Notebook\n",
    "Let's get this going in a notebook:\n",
    "```\n",
    "$ cd ~/Documents\n",
    "$ mkdir spark_examples\n",
    "$ cd spark_examples\n",
    "$ ipython notebook\n",
    "```\n",
    "\n",
    "In the notebook run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure Spark Settings\n",
    "conf=SparkConf()\n",
    "conf.setAppName(\"My App\")\n",
    "\n",
    "## Initialize SparkContext\n",
    "sc = SparkContext('local[*]', conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7f45cbee0990>\n"
     ]
    }
   ],
   "source": [
    "print sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Now move on to the first class.\n",
    "<img src=\"http://i.huffpost.com/gen/263452/images/s-BILL-AND-TED-large.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
