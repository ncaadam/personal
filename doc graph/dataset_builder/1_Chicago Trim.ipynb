{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming DG to just Chicago Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.4.0) is available! Your current version is v1.3.0.\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade."
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Spark Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure Spark Settings\n",
    "conf=SparkConf()\n",
    "conf.set(\"spark.executor.memory\", \"10g\")\n",
    "conf.set(\"spark.cores.max\", \"1\")\n",
    "conf.setAppName(\"My App\")\n",
    "\n",
    "## Initialize SparkContext\n",
    "sc = SparkContext('local[*]', conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to type cast variables\n",
    "def safe_cast(val, to_type, default=0):\n",
    "    try:\n",
    "        return to_type(val)\n",
    "    except ValueError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to filter out all doctors not in Chicago\n",
    "def chicago_filter(line):\n",
    "    five_zip = safe_cast(line[10][0:5].replace('\\\"',''), int)\n",
    "    if five_zip in zip_list:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleans unwanted quotes around data\n",
    "def clean(line):\n",
    "    new_line = []\n",
    "    for cell in line:\n",
    "        new_line.append(cell.replace('\\\"',''))\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decodes unicode\n",
    "def encode_filter(line):\n",
    "    new_line = []\n",
    "    for first in line:\n",
    "        first = first.split(',')\n",
    "        for cell in first:\n",
    "            cell = cell.encode('utf-8').strip()\n",
    "            new_line.append(cell)    \n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to filter out the quotes in every line\n",
    "def quote_filter(line):\n",
    "    new_line = []\n",
    "    for cell in line:\n",
    "        new_line.append(cell.replace('\\\"',''))\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filters NPIs in both columns of the edge data\n",
    "def filter_npis(line):\n",
    "    if line[0] in npi_dict and line[1] in npi_dict:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming to Chicago Zip Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DocGraph Node Data\n",
    "dg_node_raw = sc.textFile('data/DocGraph_Procedure.csv').map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DocGraph Edge Data\n",
    "dg_edge_raw = sc.textFile('data/DocGraph-2012-2013-Days365.csv').map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start server at: ipc:///tmp/graphlab_server-50092 - Server binary: /Users/astuckey002/anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1431703885.log\n",
      "[INFO] GraphLab Server Version: 1.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/astuckey002/Documents/Analytics/DocGraph/Dataset Builder/data/chicago_metro_zip.csv\n",
      "PROGRESS: Parsing completed. Parsed 804 lines in 0.011943 secs.\n"
     ]
    }
   ],
   "source": [
    "# Chicago Zip Codes\n",
    "chicago_zips = gl.SFrame.read_csv('data/chicago_metro_zip.csv',verbose = False)\n",
    "zip_list = list(chicago_zips['zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out the header\n",
    "dg_header = dg_node_raw.first()\n",
    "dg_node_raw = dg_node_raw.filter(lambda line: line != dg_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# line by line filtering out the quotes in each cell\n",
    "dg_node_updated = dg_node_raw.map(lambda x : quote_filter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out the zip codes not in Chicago\n",
    "dg_node_chicago = dg_node_updated.filter(lambda line: chicago_filter(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the RDD to GraphLab SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts an RDD to an SFrame in GL\n",
    "dg_node_sf = gl.SFrame.from_rdd(dg_node_chicago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data is interpreted as one column\n",
    "# we can use the unpack function in GL to create multiple columns\n",
    "dg_node_sf_u = dg_node_sf.unpack('X1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the column name dictionary\n",
    "col_names = {'X1.0':'npi','X1.1':'nppes_provider_last_org_name','X1.2':'nppes_provider_first_name','X1.3':'nppes_provider_mi',\n",
    "             'X1.4':'nppes_credentials','X1.5':'nppes_provider_gender','X1.6':'nppes_entity_code','X1.7':'nppes_provider_street1',\n",
    "             'X1.8':'nppes_provider_street2','X1.9':'nppes_provider_city','X1.10':'nppes_provider_zip',\n",
    "             'X1.11':'nppes_provider_state','X1.12':'nppes_provider_country','X1.13':'provider_type',\n",
    "             'X1.14':'medicare_participation_indicator','X1.15':'place_of_Service','X1.16':'hcpcs_code','X1.17':'line_srvc_cnt',\n",
    "             'X1.18':'bene_unique_cnt','X1.19':'bene_day_srvc_cnt','X1.20':'average_Medicare_allowed_amt',\n",
    "             'X1.21':'stdev_Medicare_allowed_amt','X1.22':'average_submitted_chrg_amt','X1.23':'stdev_submitted_chrg_amt',\n",
    "             'X1.24':'average_Medicare_payment_amt','X1.25':'stdev_Medicare_payment_amt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "dg_node_sf_u = dg_node_sf_u.rename(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the column data type dictionary\n",
    "col_types = {'line_srvc_cnt':int,'bene_unique_cnt':int,'bene_day_srvc_cnt':int,'average_Medicare_allowed_amt':float,\n",
    "             'stdev_Medicare_allowed_amt':float,'average_submitted_chrg_amt':float,'stdev_submitted_chrg_amt':float,\n",
    "             'average_Medicare_payment_amt':float,'stdev_Medicare_payment_amt':float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_srvc_cnt starting...\n",
      "line_srvc_cnt ending...\n",
      "bene_unique_cnt starting...\n",
      "bene_unique_cnt ending...\n",
      "bene_day_srvc_cnt starting...\n",
      "bene_day_srvc_cnt ending...\n",
      "average_Medicare_allowed_amt starting...\n",
      "average_Medicare_allowed_amt ending...\n",
      "stdev_Medicare_allowed_amt starting...\n",
      "stdev_Medicare_allowed_amt ending...\n",
      "average_submitted_chrg_amt starting...\n",
      "average_submitted_chrg_amt ending...\n",
      "stdev_submitted_chrg_amt starting...\n",
      "stdev_submitted_chrg_amt ending...\n",
      "average_Medicare_payment_amt starting...\n",
      "average_Medicare_payment_amt ending...\n",
      "stdev_Medicare_payment_amt starting...\n",
      "stdev_Medicare_payment_amt ending...\n"
     ]
    }
   ],
   "source": [
    "# loop through the columns and give each the appropriate data type\n",
    "for name in dg_node_sf_u.column_names():\n",
    "    if name in col_types.keys():\n",
    "        print name, 'starting...'\n",
    "        if col_types[name] is int:\n",
    "            dg_node_sf_u[name] = dg_node_sf_u[name].astype(int)\n",
    "        elif col_types[name] is float:\n",
    "            dg_node_sf_u[name] = dg_node_sf_u[name].astype(float)\n",
    "        else:\n",
    "            print 'Something went wrong with column:', name\n",
    "        print name, 'ending...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of unique NPIs in Chicago\n",
    "chi_npi_list = list(dg_node_sf_u['npi'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of these unique values for python processing speed improvements\n",
    "npi_dict = {}\n",
    "for npi in chi_npi_list:\n",
    "    npi_dict[npi] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and filter the edge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run each row through the encoding function\n",
    "dg_edge_updated = dg_edge_raw.map(lambda x : encode_filter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run earch row through the NPI filter\n",
    "dg_edge_chicago = dg_edge_updated.filter(lambda line : filter_npis(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the edge RDD to a GL SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the RDD to an SFrame using GL\n",
    "dg_edge_sf = gl.SFrame.from_rdd(dg_edge_chicago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data is interpreted as one column\n",
    "# we can use the unpack function in GL to create multiple columns \n",
    "dg_edge_sf_u = dg_edge_sf.unpack('X1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the column names dictionary and rename each column\n",
    "col_names = {'X1.0':'FirstNPI','X1.1':'SecondNPI','X1.2':'SharedTransactionCount','X1.3':'PatientTotal','X1.4':'SameDayTotal'}\n",
    "dg_edge_sf_u = dg_edge_sf_u.rename(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the column data types dictionary\n",
    "col_types = {'FirstNPI':str,'SecondNPI':str,'SharedTransactionCount':int,'PatientTotal':int,'SameDayTotal':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FirstNPI starting...\n",
      "FirstNPI ending...\n",
      "SecondNPI starting...\n",
      "SecondNPI ending...\n",
      "SharedTransactionCount starting...\n",
      "SharedTransactionCount ending...\n",
      "PatientTotal starting...\n",
      "PatientTotal ending...\n",
      "SameDayTotal starting...\n",
      "SameDayTotal ending...\n"
     ]
    }
   ],
   "source": [
    "# loop through each column and assign it the appropriate data type\n",
    "for name in dg_edge_sf_u.column_names():\n",
    "    if name in col_types.keys():\n",
    "        print name, 'starting...'\n",
    "        if col_types[name] is int:\n",
    "            dg_edge_sf_u[name] = dg_edge_sf_u[name].astype(int)\n",
    "        elif col_types[name] is float:\n",
    "            dg_edge_sf_u[name] = dg_edge_sf_u[name].astype(float)\n",
    "        elif col_types[name] is str:\n",
    "            dg_edge_sf_u[name] = dg_edge_sf_u[name].astype(str)\n",
    "        else:\n",
    "            print 'Something went wrong with column:', name\n",
    "        print name, 'ending...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the filtered nodes and edges\n",
    "dg_node_sf_u.save('data/dg_nodes_chicago.csv')\n",
    "dg_edge_sf_u.save('data/dg_edges_chicago.csv')\n",
    "\n",
    "# save the unique list of NPIs\n",
    "dg_node_sf_u[['npi']].unique().save('data/unique_npis.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
