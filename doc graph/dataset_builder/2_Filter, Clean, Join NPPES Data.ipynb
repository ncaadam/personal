{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, Clean, and Join the NPPES Data w/ DocGraph Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start server at: ipc:///tmp/graphlab_server-58208 - Server binary: /Users/astuckey002/anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1431704894.log\n",
      "[INFO] GraphLab Server Version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "from pyspark import SparkConf,SparkContext\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Spark Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure Spark Settings\n",
    "conf=SparkConf()\n",
    "conf.set(\"spark.executor.memory\", \"10g\")\n",
    "conf.set(\"spark.cores.max\", \"1\")\n",
    "conf.setAppName(\"My App\")\n",
    "\n",
    "## Initialize SparkContext\n",
    "sc = SparkContext('local[*]', conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to type cast variables\n",
    "def safe_cast(val, to_type, default=0):\n",
    "    try:\n",
    "        return to_type(val)\n",
    "    except ValueError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleans unwanted quotes around data\n",
    "def clean(line):\n",
    "    new_line=[]\n",
    "    for i in line:\n",
    "        i=i.replace('\\\"','')\n",
    "        new_line.append(i)\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filters the NPIs to the ones we care about\n",
    "def filter_npis(line):\n",
    "    npi = safe_cast(clean(line)[0],int)\n",
    "    rep_npi = safe_cast(clean(line)[2],int)\n",
    "    \n",
    "    if (npi in npi_dict) or (rep_npi in npi_dict):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some preliminary cleaning to the NPPES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the NPPES data\n",
    "with open('data/npidata_20050523-20150208.csv','r') as f:\n",
    "    nppes_pre = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data back to a new CSV file as tab delimited\n",
    "with open('data/nppes_fixed.csv','w') as f:\n",
    "    for line in nppes_pre:\n",
    "        f.write(line.replace('\\\",\"',\"\\t\").replace('\\\"',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the CSV file into Spark\n",
    "raw_data = sc.textFile('data/nppes_fixed.csv').map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the header for the file\n",
    "header = raw_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/astuckey002/Documents/Analytics/DocGraph/Dataset Builder/data/unique_npis.csv\n",
      "PROGRESS: Parsing completed. Parsed 25921 lines in 0.019065 secs.\n"
     ]
    }
   ],
   "source": [
    "# get the unique NPI list from our data\n",
    "npi_list = gl.SFrame.read_csv('data/unique_npis.csv', verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the unique NPI list into a dictionary for quicker python processing speeds\n",
    "npi_dict = {}\n",
    "for line in npi_list['npi']:\n",
    "    npi = safe_cast(line,int)\n",
    "    npi_dict[npi] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the data by only the NPIs in Chicago\n",
    "filtered_data = raw_data.filter(lambda line: filter_npis(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the RDD to an SFrame in GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert rdd to SFrame\n",
    "nppes_sf = gl.SFrame.from_rdd(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data is interpreted as one column\n",
    "# we can use the unpack function in GL to create multiple columns\n",
    "nppes_sf_u = nppes_sf.unpack('X1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a header dictionary\n",
    "header_dict = {}\n",
    "y = 0\n",
    "for x in header:\n",
    "    header_dict[y] = x\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the header dictionary to rename the columns\n",
    "for col in nppes_sf_u.column_names():\n",
    "    nppes_sf_u.rename({col:header_dict[int(col[3:])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing column: Replacement NPI\n",
      "Removing column: NPI Deactivation Reason Code\n",
      "Removing column: Other Provider Identifier Issuer_20\n",
      "Removing column: Other Provider Identifier Issuer_25\n",
      "Removing column: Other Provider Identifier Issuer_26\n",
      "Removing column: Other Provider Identifier Issuer_27\n",
      "Removing column: Other Provider Identifier Issuer_29\n",
      "Removing column: Other Provider Identifier Issuer_30\n",
      "Removing column: Other Provider Identifier Issuer_31\n",
      "Removing column: Other Provider Identifier Issuer_32\n",
      "Removing column: Other Provider Identifier Issuer_33\n",
      "Removing column: Other Provider Identifier Issuer_34\n",
      "Removing column: Other Provider Identifier_35\n",
      "Removing column: Other Provider Identifier Type Code_35\n",
      "Removing column: Other Provider Identifier State_35\n",
      "Removing column: Other Provider Identifier Issuer_35\n",
      "Removing column: Other Provider Identifier_36\n",
      "Removing column: Other Provider Identifier Type Code_36\n",
      "Removing column: Other Provider Identifier State_36\n",
      "Removing column: Other Provider Identifier Issuer_36\n",
      "Removing column: Other Provider Identifier_37\n",
      "Removing column: Other Provider Identifier Type Code_37\n",
      "Removing column: Other Provider Identifier State_37\n",
      "Removing column: Other Provider Identifier Issuer_37\n",
      "Removing column: Other Provider Identifier_38\n",
      "Removing column: Other Provider Identifier Type Code_38\n",
      "Removing column: Other Provider Identifier State_38\n",
      "Removing column: Other Provider Identifier Issuer_38\n",
      "Removing column: Other Provider Identifier_39\n",
      "Removing column: Other Provider Identifier Type Code_39\n",
      "Removing column: Other Provider Identifier State_39\n",
      "Removing column: Other Provider Identifier Issuer_39\n",
      "Removing column: Other Provider Identifier_40\n",
      "Removing column: Other Provider Identifier Type Code_40\n",
      "Removing column: Other Provider Identifier State_40\n",
      "Removing column: Other Provider Identifier Issuer_40\n",
      "Removing column: Other Provider Identifier_41\n",
      "Removing column: Other Provider Identifier Type Code_41\n",
      "Removing column: Other Provider Identifier State_41\n",
      "Removing column: Other Provider Identifier Issuer_41\n",
      "Removing column: Other Provider Identifier_42\n",
      "Removing column: Other Provider Identifier Type Code_42\n",
      "Removing column: Other Provider Identifier State_42\n",
      "Removing column: Other Provider Identifier Issuer_42\n",
      "Removing column: Other Provider Identifier_43\n",
      "Removing column: Other Provider Identifier Type Code_43\n",
      "Removing column: Other Provider Identifier State_43\n",
      "Removing column: Other Provider Identifier Issuer_43\n",
      "Removing column: Other Provider Identifier_44\n",
      "Removing column: Other Provider Identifier Type Code_44\n",
      "Removing column: Other Provider Identifier State_44\n",
      "Removing column: Other Provider Identifier Issuer_44\n",
      "Removing column: Other Provider Identifier_45\n",
      "Removing column: Other Provider Identifier Type Code_45\n",
      "Removing column: Other Provider Identifier State_45\n",
      "Removing column: Other Provider Identifier Issuer_45\n",
      "Removing column: Other Provider Identifier_46\n",
      "Removing column: Other Provider Identifier Type Code_46\n",
      "Removing column: Other Provider Identifier State_46\n",
      "Removing column: Other Provider Identifier Issuer_46\n",
      "Removing column: Other Provider Identifier_47\n",
      "Removing column: Other Provider Identifier Type Code_47\n",
      "Removing column: Other Provider Identifier State_47\n",
      "Removing column: Other Provider Identifier Issuer_47\n",
      "Removing column: Other Provider Identifier_48\n",
      "Removing column: Other Provider Identifier Type Code_48\n",
      "Removing column: Other Provider Identifier State_48\n",
      "Removing column: Other Provider Identifier Issuer_48\n",
      "Removing column: Other Provider Identifier_49\n",
      "Removing column: Other Provider Identifier Type Code_49\n",
      "Removing column: Other Provider Identifier State_49\n",
      "Removing column: Other Provider Identifier Issuer_49\n",
      "Removing column: Other Provider Identifier_50\n",
      "Removing column: Other Provider Identifier Type Code_50\n",
      "Removing column: Other Provider Identifier State_50\n",
      "Removing column: Other Provider Identifier Issuer_50\n"
     ]
    }
   ],
   "source": [
    "# remove columns that have zero data\n",
    "for col in nppes_sf_u.column_names():\n",
    "    counter = 0\n",
    "    temp_data = nppes_sf_u[col]\n",
    "    for cell in temp_data:\n",
    "        if cell != \"\":\n",
    "            counter += 1\n",
    "        if counter > 0:\n",
    "            break\n",
    "    \n",
    "    if counter == 0:\n",
    "        nppes_sf_u.remove_column(col)\n",
    "        print \"Removing column:\", col\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename the joining column name to match the DG dataset\n",
    "nppes_sf_u = nppes_sf_u.rename({'NPI':'npi'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the DG Chicago Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,int,int,int,float,float,float,float,float,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/astuckey002/Documents/Analytics/DocGraph/Dataset Builder/data/dg_nodes_chicago.csv\n",
      "PROGRESS: Parsing completed. Parsed 264209 lines in 1.68642 secs.\n"
     ]
    }
   ],
   "source": [
    "# read in the docgraph data\n",
    "dg_chicago_nodes = gl.SFrame.read_csv('data/dg_nodes_chicago.csv', verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the data on the NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use join to combine the two files via the unique identifier (NPI)\n",
    "joined_data = dg_chicago_nodes.join(nppes_sf_u,on = 'npi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the resulting dataset\n",
    "joined_data.save('data/dg_nppes_chicago_joined.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
