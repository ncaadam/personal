{
 "metadata": {
  "name": "",
  "signature": "sha256:f42dff4dc1a253ebd99b809a77d39eb060ba300ab806d770f41e79256ce1d90a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import pandas\n",
      "import pandas as pd\n",
      "\n",
      "#import distance for matching algo\n",
      "import scipy.spatial.distance as distance\n",
      "\n",
      "#import the Python3 division functionality\n",
      "from __future__ import division\n",
      "\n",
      "#import sklearn packages for training & testing models\n",
      "from sklearn.svm import SVC, SVR\n",
      "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import accuracy_score,mean_squared_error\n",
      "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
      "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
      "\n",
      "#import the datetime package\n",
      "from datetime import datetime\n",
      "\n",
      "#import random for dataset sampling\n",
      "import random\n",
      "\n",
      "#import json for exporting\n",
      "import json\n",
      "\n",
      "\n",
      "def matching_columns(data,dataset_abbreviation,column_new_names_dict):\n",
      "    \"\"\"\n",
      "    Takes a full dataset, drops all columns but the ones identified in 'column_new_names_dict', \n",
      "    and renames the columns using the values in 'column_new_names_dict'. It also appends the abbreviation to\n",
      "    the front of each column name. \n",
      "    \n",
      "    Returns a pandas dataframe\n",
      "    \n",
      "    data - pandas data frame\n",
      "    dataset_abbreviation - an abbreviation to be used throughout the script (String)\n",
      "    column_new_names_dict - a dictionary with the original column names as keys (string) and the values as what you'd like to rename the column as (string)\n",
      "    \"\"\"\n",
      "    if isinstance(column_new_names_dict, dict) and isinstance(dataset_abbreviation, str):\n",
      "        subset = data[column_new_names_dict.keys()]\n",
      "        for key,value in column_new_names_dict.iteritems():\n",
      "            if column_new_names_dict[key][:len(dataset_abbreviation)] != dataset_abbreviation:\n",
      "                column_new_names_dict[key] = str(dataset_abbreviation) + '_' + value\n",
      "            else:\n",
      "                #print \"DATASET ALREADY NAMED\"\n",
      "                continue\n",
      "        subset_renamed = subset.rename(columns = column_new_names_dict)\n",
      "        return subset_renamed\n",
      "    else:\n",
      "        print \"PROBLEM\"\n",
      "\n",
      "        \n",
      "def import_data(path,sheet_no = 0, row_skip = 0):\n",
      "    \"\"\"\n",
      "    Imports a dataset from the path variable and exports it as a pandas dataframe\n",
      "    \"\"\"\n",
      "    extension = path[path.rfind('.')+1:]\n",
      "    if extension == 'xlsx' or extension == 'xls':\n",
      "        #bring in your data\n",
      "        excel = pd.ExcelFile(path)\n",
      "        #parse the data into a pandas dataframe - parse accepts arguments for sheet name/number and rows to skip (for example)\n",
      "        data = excel.parse(sheetname=sheet_no,skiprows=row_skip,)\n",
      "        return data\n",
      "    elif extension == 'csv':\n",
      "        csv = pd.read_csv(path)\n",
      "        return csv\n",
      "    else:\n",
      "        return \"PROBLEM\"\n",
      "\n",
      "    \n",
      "def get_distances(xa,xb,method):\n",
      "    \"\"\"\n",
      "    xa - 1-D array\n",
      "    xb - 2-D array\n",
      "    method - metric used to find the distance between each pair of the dataset\n",
      "             options for this argument are - 'braycurtis\u2019,\u2018canberra\u2019,\u2018chebyshev\u2019,\u2018cityblock\u2019,\u2018correlation\u2019,\u2018cosine\u2019,\u2018dice\u2019,\u2018euclidean\u2019,\u2018hamming\u2019,\u2018jaccard\u2019,\u2018kulsinski\u2019,\u2018mahalanobis\u2019,\u2018matching\u2019,\u2018minkowski\u2019,\u2018rogerstanimoto\u2019,\u2018russellrao\u2019,\u2018seuclidean\u2019,\u2018sokalmichener\u2019,\u2018sokalsneath\u2019,\u2018sqeuclidean\u2019,\u2018wminkowski\u2019,\u2018yule\u2019\n",
      "    \"\"\"\n",
      "    possibilities = [\"braycurtis\",\"canberra\",\"chebyshev\",\"cityblock\",\"correlation\",\"cosine\",\"dice\",\"euclidean\",\"hamming\",\"jaccard\",\"kulsinski\",\"mahalanobis\",\"matching\",\"minkowski\",\"rogerstanimoto\",\"russellrao\",\"seuclidean\",\"sokalmichener\",\"sokalsneath\",\"sqeuclidean\",\"wminkowski\",\"yule\"]\n",
      "    if method in possibilities:\n",
      "        try:\n",
      "            distances = distance.cdist(xa,xb,metric = method)\n",
      "        except:\n",
      "            distances = []\n",
      "        finally:\n",
      "            return distances\n",
      "\n",
      "def check_accuracy(data, xa_column_name, xb_column_name):\n",
      "    \"\"\"\n",
      "    Checks the accuracy of two columns in the same dataframe and returns the percent that are the same.\n",
      "    \n",
      "    data - pandas dataframe\n",
      "    xa_column_name - first column to be compared\n",
      "    xb_column_name - second column to be compared\n",
      "    \"\"\"\n",
      "    num_of_same = len(data[data[xa_column_name] == data[xb_column_name]])\n",
      "    num_total = len(data)\n",
      "    output = (num_of_same/num_total)*100\n",
      "    return output\n",
      "\n",
      "def drop_and_split(data,column_to_drop = \"\"):\n",
      "    \"\"\"\n",
      "    Drops the column indicated in the 'column_to_drop' parameter and splits the data set into train and test datasets.\n",
      "    \n",
      "    Uses 20% of the data for the test dataset\n",
      "    \n",
      "    Returns train,test as pandas dataframes\n",
      "    \n",
      "    data - pandas dataframe\n",
      "    column_to_drop - the name of the column to drop from the dataset(string)\n",
      "    \"\"\"\n",
      "    #one_drop = data.drop(column_to_drop,1)\n",
      "    #column_names = list(one_drop.columns.values)\n",
      "    train, test = train_test_split(data, test_size=0.20, random_state = 24)\n",
      "    train = pd.DataFrame(train,columns=data.columns.values.tolist())\n",
      "    test = pd.DataFrame(test,columns=data.columns.values.tolist())\n",
      "    return train,test\n",
      "\n",
      "        \n",
      "def create_input_file(method, stat_matching_dict,donor_data, donor_abbreviation, donor_columns, client_final, client_abbreviation):\n",
      "    #convert distances to a dataframe and add IDs as indices\n",
      "    distancesDF = pd.DataFrame(stat_matching_dict, index=pd.np.array(client_final[[client_abbreviation + '_ID']][client_abbreviation + '_ID']))\n",
      "    distancesDF.columns = pd.np.array(donor_final[[donor_abbreviation + '_ID']][donor_abbreviation + '_ID'])\n",
      "\n",
      "    matched_records = distancesDF.idxmin(axis=1).to_dict()\n",
      "    print method + \": IDs indexed...\" + str(datetime.now())\n",
      "    \n",
      "    donor_input = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "    donor_input.describe()\n",
      "    print method + \": Donor Input created...\" + str(datetime.now())\n",
      "    \n",
      "    #assemble input file fields from client and donor datasets based on matched IDs\n",
      "    input_file_list = []\n",
      "\n",
      "    for client_id, donor_id in matched_records.iteritems():\n",
      "        matched_record = donor_input[donor_input[donor_abbreviation + '_ID'] == donor_id]\n",
      "        matched_record[client_abbreviation + '_ID'] = client_id\n",
      "        input_file_list.append(matched_record)\n",
      "        \n",
      "    print method + \": matched records found and created...\" + str(datetime.now())\n",
      "\n",
      "    input_file = pd.concat(input_file_list)\n",
      "    print method + \": input file concatenated...\" + str(datetime.now())\n",
      "\n",
      "    #merge the donor data with the client data for comparison\n",
      "    input_file = pd.merge(input_file, client_final, how = 'left', left_on=client_abbreviation + '_ID', right_on=client_abbreviation + '_ID')\n",
      "    print method + \": input file merged...\" + str(datetime.now())\n",
      "    \n",
      "    input_file.to_csv(\"../../../../data/synthetic_population/outputs/\" + method + \".csv\")\n",
      "    print method + \": input file saved...\" + str(datetime.now())\n",
      "    print method, \"is complete\", str(datetime.now())\n",
      "\n",
      "    \n",
      "def ml_matching(client,donor,p_type,dependent,independent,donor_abbreviation,client_abbreviation):    \n",
      "    acc_dict = {}\n",
      "    \n",
      "    donor_dep = []\n",
      "    donor_ind = ''\n",
      "    client_dep = []\n",
      "    client_ind = ''\n",
      "\n",
      "    for col in donor.columns.values:\n",
      "        for dep in dependent:\n",
      "            if dep in col:\n",
      "                donor_dep.append(col)\n",
      "        if independent in col:\n",
      "            donor_ind = col\n",
      "    \n",
      "    for col in client.columns.values:\n",
      "        for dep in dependent:\n",
      "            if dep in col:\n",
      "                client_dep.append(col)\n",
      "        if independent in col:\n",
      "            client_ind = col\n",
      "\n",
      "    #for col in train.columns.values:\n",
      "    #    if col.find(donor_ind) < 0 and col.find(\"ID\") < 0:\n",
      "    #        donor_dep.append(col)\n",
      "    #    elif col.find(y_v) > -1 and col.find(donor_abbreviation) > -1:\n",
      "    #        donor_ind = col\n",
      "    #for col in XA.columns.values:\n",
      "    #    if col.find(y_v) < 0 and col.find(\"ID\") < 0:\n",
      "    #        x_vars.append(col)\n",
      "    #    elif col.find(y_v) > -1 and col.find(client_abbreviation) > -1:\n",
      "    #        y_var = col\n",
      "\n",
      "    d_train, d_test = drop_and_split(donor)\n",
      "    \n",
      "    if p_type == 'r':\n",
      "        #SVM\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf = SVR()\n",
      "        clf.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_SVM'\n",
      "        d_train_x[d_new_col_name] = clf.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_SVM'\n",
      "        c_x[c_new_col_name] = clf.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['SVM'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        #KNN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf2 = KNeighborsRegressor()\n",
      "        clf2.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_KNN'\n",
      "        d_train_x[d_new_col_name] = clf2.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf2.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_KNN'\n",
      "        c_x[c_new_col_name] = clf2.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['KNN'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        #LIN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf3 = LinearRegression()\n",
      "        clf3.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_LIN'\n",
      "        d_train_x[d_new_col_name] = clf3.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf3.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_LIN'\n",
      "        c_x[c_new_col_name] = clf3.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['LIN'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        #Decision Tree    \n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf4 = DecisionTreeRegressor()\n",
      "        clf4.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_DT'\n",
      "        d_train_x[d_new_col_name] = clf4.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf4.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_DT'\n",
      "        c_x[c_new_col_name] = clf4.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['DT'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        return acc_dict\n",
      "    \n",
      "    elif p_type == 'c':\n",
      "        #SVM\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "    \n",
      "        clf = SVC()\n",
      "        clf.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_SVM'\n",
      "        d_train_x[d_new_col_name] = clf.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_SVM'\n",
      "        c_x[c_new_col_name] = clf.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['SVM']= client_acc, train_acc, test_acc\n",
      "        #accuracy_score(list(test[y_var]),list(test[new_col_name]))*100\n",
      "        \n",
      "        #KNN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf2 = KNeighborsClassifier()\n",
      "        clf2.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_KNN'\n",
      "        d_train_x[d_new_col_name] = clf2.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf2.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_KNN'\n",
      "        c_x[c_new_col_name] = clf2.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['KNN'] = client_acc, train_acc, test_acc\n",
      "\n",
      "\n",
      "        #Log Reg\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf3 = LogisticRegression()\n",
      "        clf3.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_LOG'\n",
      "        d_train_x[d_new_col_name] = clf3.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf3.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_LOG'\n",
      "        c_x[c_new_col_name] = clf3.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['LOG'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        #Decision Tree\n",
      "        clf4 = DecisionTreeClassifier()\n",
      "        clf4.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_DT'\n",
      "        d_train_x[d_new_col_name] = clf4.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf4.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_DT'\n",
      "        c_x[c_new_col_name] = clf4.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['DT'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        return acc_dict\n",
      "    else:\n",
      "        print \"the prediction type must be a regression or a classifier\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 430
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import the client data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Change the client abbreviation variable to an identifiable abbreviation you'd like to add to the front of your column names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#client abbreviation that will be used throughout the script\n",
      "client_abbreviation = 'PUMD'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Select the columns you'd like to match in the key of the dictionary and rename it in the value of the dictionary. (e.g. {'random_variable_name':'meaningful_variable_name'})\n",
      "\n",
      "Do not worry about adding dataset indicators in the variable names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#identify the columns we're interested in - change the varaible names here\n",
      "client_columns = {'NEWID':'ID','SEX_REF':'SEX','AGE_REF':'AGE','FSALARYX':'SALARY','STATE':'STATE_CODE',\n",
      "                  'CUTENURE':'ORIG_HOUSE_STATUS'}\n",
      "#import the client dataset - if the dataset is large, this may take minutes to finish\n",
      "client_data = import_data(\"../../../../data/synthetic_population/Interview_2013_FMLI_all.xlsx\")\n",
      "#grab the columns we're interested in and change the column names to more meaningful descriptors\n",
      "client_filtered = matching_columns(client_data,client_abbreviation,client_columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Transform the client data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#map values to different values to be consistent across datasets\n",
      "client_filtered[client_abbreviation + '_' + 'NEW_HOME_STATUS'] = client_filtered[client_abbreviation + '_' + 'ORIG_HOUSE_STATUS'].map({1:1,2:1,3:1,4:2,5:3,6:3})\n",
      "\n",
      "#import state code data\n",
      "state_codes = import_data('../../../../data/synthetic_population/State Codes.csv')\n",
      "\n",
      "#create a dictionary with this structure {'State Code':'State Abbreviation'}\n",
      "state_code_dict = dict(zip(state_codes.Code, state_codes.Abb))\n",
      "\n",
      "#transform the state codes into state abbreviations based on our state code data\n",
      "client_filtered[client_abbreviation + '_' + 'STATE_ABB'] = client_filtered[client_abbreviation + '_' + 'STATE_CODE'].map(state_code_dict)\n",
      "\n",
      "#drop the original columns that were transformed\n",
      "client_final = client_filtered.drop([client_abbreviation + '_' + 'STATE_CODE',\n",
      "                                     client_abbreviation + '_' + 'ORIG_HOUSE_STATUS'],1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import the donor data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#donor abbreviation that will be used throughout the script\n",
      "donor_abbreviation = \"SBI\"\n",
      "\n",
      "#identify the columns we're interested in - change the varaible names here\n",
      "donor_columns = {'ID':'ID','OCALC_4':'AGE','OCALC_27':'SALARY','OCALC_10':'SEX','STATE':'STATE','G4':'HOME_STATUS'}\n",
      "\n",
      "#pull in donor dataset\n",
      "donor_data = import_data('../../../../data/synthetic_population/SBI_Complete.csv')\n",
      "\n",
      "#filter for the columns that we're interested in - this also renameds the columns\n",
      "donor_filtered = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "donor_final = donor_filtered"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Start Here - Stat Match"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#choose number of client records to match and pull an array of that many records at random\n",
      "#n = 10000\n",
      "#client_final = client_final.ix[random.sample(client_final.index,n)]\n",
      "#len(client_final)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "method = 'cityblock'\n",
      "match_file = pd.read_csv('../../../../data/synthetic_population/outputs/AGE_SEX_match/' + method + '.csv')\n",
      "match_file = match_file.drop('Unnamed: 0',1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match_file.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "(25822, 12)"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create matrix of distance measurements\n",
      "XA = client_final[['PUMD_AGE','PUMD_NEW_HOME_STATUS']]\n",
      "#[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "XB = donor_final[['SBI_AGE','SBI_HOME_STATUS']]\n",
      "#[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a dictionary with the statistical matching method as the key and the matching array as the value\n",
      "stat_matching_dict = {}\n",
      "potential_methods = [\"braycurtis\",\"cityblock\",\"correlation\",\"cosine\",\"euclidean\",\"minkowski\",\"sqeuclidean\"]\n",
      "for method in potential_methods:\n",
      "    output = get_distances(XA,XB,method)\n",
      "    stat_matching_dict[method] = output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for method in potential_methods:\n",
      "    create_input_file(method,stat_matching_dict[method],donor_data, donor_abbreviation, donor_columns, client_final, client_abbreviation)\n",
      "    print \"Method - \" + method, \"complete\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "braycurtis: IDs indexed...2015-02-03 09:53:44.912900\n",
        "braycurtis: Donor Input created...2015-02-03 09:53:44.947226\n",
        "braycurtis: matched records found and created...2015-02-03 09:54:03.332346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "braycurtis: input file concatenated...2015-02-03 09:54:18.969872"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "braycurtis: input file merged...2015-02-03 09:54:18.988871\n",
        "braycurtis: input file saved...2015-02-03 09:54:19.120331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "braycurtis is complete 2015-02-03 09:54:19.120782\n",
        "Method - braycurtis"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "cityblock: IDs indexed...2015-02-03 09:54:23.714435"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cityblock: Donor Input created...2015-02-03 09:54:23.738685\n",
        "cityblock: matched records found and created...2015-02-03 09:54:43.264885"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cityblock: input file concatenated...2015-02-03 09:55:04.483270"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cityblock: input file merged...2015-02-03 09:55:04.518153\n",
        "cityblock: input file saved...2015-02-03 09:55:04.765080"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cityblock is complete 2015-02-03 09:55:04.766065\n",
        "Method - cityblock"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "correlation: IDs indexed...2015-02-03 09:55:11.913209"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "correlation: Donor Input created...2015-02-03 09:55:11.935718\n",
        "correlation: matched records found and created...2015-02-03 09:55:33.467761"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "correlation: input file concatenated...2015-02-03 09:55:49.404423"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "correlation: input file merged...2015-02-03 09:55:49.416984\n",
        "correlation: input file saved...2015-02-03 09:55:49.505420"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "correlation is complete 2015-02-03 09:55:49.505760\n",
        "Method - correlation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "cosine: IDs indexed...2015-02-03 09:55:55.223716"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cosine: Donor Input created...2015-02-03 09:55:55.246024\n",
        "cosine: matched records found and created...2015-02-03 09:56:11.204780"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cosine: input file concatenated...2015-02-03 09:56:28.253336"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cosine: input file merged...2015-02-03 09:56:28.264246\n",
        "cosine: input file saved...2015-02-03 09:56:28.351984"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cosine is complete 2015-02-03 09:56:28.352327\n",
        "Method - cosine"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "euclidean: IDs indexed...2015-02-03 09:56:35.387773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "euclidean: Donor Input created...2015-02-03 09:56:35.408439\n",
        "euclidean: matched records found and created...2015-02-03 09:56:51.246256"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "euclidean: input file concatenated...2015-02-03 09:57:05.899371"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "euclidean: input file merged...2015-02-03 09:57:05.914172\n",
        "euclidean: input file saved...2015-02-03 09:57:06.029338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "euclidean is complete 2015-02-03 09:57:06.029658\n",
        "Method - euclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "minkowski: IDs indexed...2015-02-03 09:57:11.668035"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "minkowski: Donor Input created...2015-02-03 09:57:11.676208\n",
        "minkowski: matched records found and created...2015-02-03 09:57:26.640813"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "minkowski: input file concatenated...2015-02-03 09:57:40.255785"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "minkowski: input file merged...2015-02-03 09:57:40.266417\n",
        "minkowski: input file saved...2015-02-03 09:57:40.372347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "minkowski is complete 2015-02-03 09:57:40.372838\n",
        "Method - minkowski"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n",
        "sqeuclidean: IDs indexed...2015-02-03 09:57:46.300892"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sqeuclidean: Donor Input created...2015-02-03 09:57:46.318820\n",
        "sqeuclidean: matched records found and created...2015-02-03 09:58:02.797419"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sqeuclidean: input file concatenated...2015-02-03 09:58:20.486146"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sqeuclidean: input file merged...2015-02-03 09:58:20.502599\n",
        "sqeuclidean: input file saved...2015-02-03 09:58:20.613434"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sqeuclidean is complete 2015-02-03 09:58:20.613824\n",
        "Method - sqeuclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#select statistical matching method to use\n",
      "potential_methods = [\"braycurtis\",\"cityblock\",\"correlation\",\"cosine\",\"euclidean\",\"minkowski\",\"sqeuclidean\"]\n",
      "variables = ['SEX','AGE','HOME','SALARY']\n",
      "output_dict = {}\n",
      "for method in potential_methods:\n",
      "    print method, \"has started...\"\n",
      "    match_file = pd.read_csv('../../../../data/synthetic_population/outputs/AGE_SEX_match/' + method + '.csv')\n",
      "    match_file = match_file.drop('Unnamed: 0',1)\n",
      "    #donor_input = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "    temp_dict = {}\n",
      "    for var in variables:\n",
      "        print var, \"has started...\"\n",
      "        if var in ['SEX']:\n",
      "            try:\n",
      "                accuracy = accuracy_score(match_file[client_abbreviation + '_' + var],\n",
      "                                          match_file[donor_abbreviation + '_' + var])\n",
      "            except:\n",
      "                accuracy = -1\n",
      "                continue\n",
      "        elif var in ['HOME']:\n",
      "            try:\n",
      "                accuracy = accuracy_score(match_file[client_abbreviation + '_NEW_HOME_STATUS'],\n",
      "                                          match_file[donor_abbreviation + '_HOME_STATUS'])\n",
      "            except:\n",
      "                accuracy = -1\n",
      "                continue\n",
      "        elif var in ['AGE','SALARY']:\n",
      "            try:\n",
      "                accuracy = mean_squared_error(match_file[client_abbreviation + '_' + var],\n",
      "                                              match_file[donor_abbreviation + '_' + var])\n",
      "            except:\n",
      "                accuracy = -1\n",
      "                continue\n",
      "        else:\n",
      "            print \"WTF\"\n",
      "        temp_dict[var] = accuracy\n",
      "        print var, \"has completed...\"      \n",
      "    output_dict[method] = temp_dict\n",
      "    print method, \"has completed...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "braycurtis has started...\n",
        "SEX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "braycurtis has completed...\n",
        "cityblock has started...\n",
        "SEX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "cityblock has completed...\n",
        "correlation has started...\n",
        "SEX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "correlation has completed...\n",
        "cosine has started...\n",
        "SEX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "cosine has completed...\n",
        "euclidean has started...\n",
        "SEX has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "euclidean has completed...\n",
        "minkowski has started...\n",
        "SEX has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "minkowski has completed...\n",
        "sqeuclidean has started...\n",
        "SEX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has started...\n",
        "SEX has completed...\n",
        "AGE has started...\n",
        "AGE has completed...\n",
        "HOME has started...\n",
        "HOME has completed...\n",
        "SALARY has started...\n",
        "SALARY has completed...\n",
        "sqeuclidean has completed...\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../../../../data/synthetic_population/outputs/matching_ml_output.json\", 'w') as f:\n",
      "    json.dump(output_dict, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Start Here - ML Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create matrix of distance measurements\n",
      "XA = client_final[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "#[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "XB = donor_final[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]\n",
      "#[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]\n",
      "\n",
      "# replace NaNs\n",
      "XB['SBI_HOME_STATUS'] = pd.np.where(XB['SBI_HOME_STATUS'].isnull(),0,XB['SBI_HOME_STATUS'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 431
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build model based on donor dataset\n",
      "x_v = ['SALARY', 'SEX']#, 'HOME']\n",
      "y_v = 'AGE'\n",
      "p_type = 'r'\n",
      "ml_matching(XA,XB,p_type,x_v,y_v,donor_abbreviation,client_abbreviation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 436,
       "text": [
        "{'DT': (660.60803341403994, 99.307152616292157, 243.50489924986883),\n",
        " 'KNN': (478.91228254976375, 172.87008859674191, 199.96649142857143),\n",
        " 'LIN': (324.26622249278068, 197.41363315220818, 179.1043565257076),\n",
        " 'SVM': (331.24774811884259, 180.75008244483783, 174.61596596242759)}"
       ]
      }
     ],
     "prompt_number": 436
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Overflow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ORIGINAL\n",
      "#select statistical matching method to use\n",
      "#potential_methods = [\"braycurtis\",\"cityblock\",\"correlation\",\"cosine\",\"euclidean\",\"minkowski\",\"sqeuclidean\"]\n",
      "variables = ['SEX', 'AGE'] #HOME SALARY\n",
      "output_dict = {}\n",
      "for method in potential_methods:\n",
      "    print method, \"has started...\"\n",
      "    match_file = pd.read_csv('../../../data/synthetic_population/outputs/' + method + '.csv')\n",
      "    match_file = match_file.drop('Unnamed: 0',1)\n",
      "    donor_input = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "    temp_dict = {}\n",
      "    for var in variables:\n",
      "        print var, \"has started...\"\n",
      "        if var in ['SEX','HOME']:\n",
      "            this_type = 'c'\n",
      "        elif var in ['AGE','SALARY']:\n",
      "            this_type = 'r'\n",
      "        else:\n",
      "            print \"WTF\"\n",
      "        try:\n",
      "            temp_dict[var] = predict(match_file,this_type,client_abbreviation,var)\n",
      "        except:\n",
      "            temp_dict[var] = \"Error\"\n",
      "            continue\n",
      "        print var, \"has completed...\"      \n",
      "    output_dict[method] = temp_dict\n",
      "    print method, \"has completed...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}