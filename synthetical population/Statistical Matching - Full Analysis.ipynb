{
 "metadata": {
  "name": "",
  "signature": "sha256:6a4d3542817c448a3f315944418f746fc39ad3c91b14bab2271ac758bc5a897b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import pandas\n",
      "import pandas as pd\n",
      "\n",
      "#import distance for matching algo\n",
      "import scipy.spatial.distance as distance\n",
      "\n",
      "#import the Python3 division functionality\n",
      "from __future__ import division\n",
      "\n",
      "#import sklearn packages for training & testing models\n",
      "from sklearn.svm import SVC, SVR\n",
      "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import accuracy_score,mean_squared_error\n",
      "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
      "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
      "\n",
      "#import the datetime package\n",
      "from datetime import datetime\n",
      "\n",
      "#import random for dataset sampling\n",
      "import random\n",
      "\n",
      "#import json for exporting\n",
      "import json\n",
      "\n",
      "\n",
      "def matching_columns(data,dataset_abbreviation,column_new_names_dict):\n",
      "    \"\"\"\n",
      "    Takes a full dataset, drops all columns but the ones identified in 'column_new_names_dict', \n",
      "    and renames the columns using the values in 'column_new_names_dict'. It also appends the abbreviation to\n",
      "    the front of each column name. \n",
      "    \n",
      "    Returns a pandas dataframe\n",
      "    \n",
      "    data - pandas data frame\n",
      "    dataset_abbreviation - an abbreviation to be used throughout the script (String)\n",
      "    column_new_names_dict - a dictionary with the original column names as keys (string) and the values as what you'd like to rename the column as (string)\n",
      "    \"\"\"\n",
      "    if isinstance(column_new_names_dict, dict) and isinstance(dataset_abbreviation, str):\n",
      "        subset = data[column_new_names_dict.keys()]\n",
      "        for key,value in column_new_names_dict.iteritems():\n",
      "            if column_new_names_dict[key][:len(dataset_abbreviation)] != dataset_abbreviation:\n",
      "                column_new_names_dict[key] = str(dataset_abbreviation) + '_' + value\n",
      "            else:\n",
      "                #print \"DATASET ALREADY NAMED\"\n",
      "                continue\n",
      "        subset_renamed = subset.rename(columns = column_new_names_dict)\n",
      "        return subset_renamed\n",
      "    else:\n",
      "        print \"PROBLEM\"\n",
      "\n",
      "        \n",
      "def import_data(path,sheet_no = 0, row_skip = 0):\n",
      "    \"\"\"\n",
      "    Imports a dataset from the path variable and exports it as a pandas dataframe\n",
      "    \"\"\"\n",
      "    extension = path[path.rfind('.')+1:]\n",
      "    if extension == 'xlsx' or extension == 'xls':\n",
      "        #bring in your data\n",
      "        excel = pd.ExcelFile(path)\n",
      "        #parse the data into a pandas dataframe - parse accepts arguments for sheet name/number and rows to skip (for example)\n",
      "        data = excel.parse(sheetname=sheet_no,skiprows=row_skip,)\n",
      "        return data\n",
      "    elif extension == 'csv':\n",
      "        csv = pd.read_csv(path)\n",
      "        return csv\n",
      "    else:\n",
      "        return \"PROBLEM\"\n",
      "\n",
      "    \n",
      "def get_distances(xa,xb,method):\n",
      "    \"\"\"\n",
      "    xa - 1-D array\n",
      "    xb - 2-D array\n",
      "    method - metric used to find the distance between each pair of the dataset\n",
      "             options for this argument are - 'braycurtis\u2019,\u2018canberra\u2019,\u2018chebyshev\u2019,\u2018cityblock\u2019,\u2018correlation\u2019,\u2018cosine\u2019,\u2018dice\u2019,\u2018euclidean\u2019,\u2018hamming\u2019,\u2018jaccard\u2019,\u2018kulsinski\u2019,\u2018mahalanobis\u2019,\u2018matching\u2019,\u2018minkowski\u2019,\u2018rogerstanimoto\u2019,\u2018russellrao\u2019,\u2018seuclidean\u2019,\u2018sokalmichener\u2019,\u2018sokalsneath\u2019,\u2018sqeuclidean\u2019,\u2018wminkowski\u2019,\u2018yule\u2019\n",
      "    \"\"\"\n",
      "    possibilities = [\"braycurtis\",\"canberra\",\"chebyshev\",\"cityblock\",\"correlation\",\"cosine\",\"dice\",\"euclidean\",\"hamming\",\"jaccard\",\"kulsinski\",\"mahalanobis\",\"matching\",\"minkowski\",\"rogerstanimoto\",\"russellrao\",\"seuclidean\",\"sokalmichener\",\"sokalsneath\",\"sqeuclidean\",\"wminkowski\",\"yule\"]\n",
      "    if method in possibilities:\n",
      "        try:\n",
      "            distances = distance.cdist(xa,xb,metric = method)\n",
      "        except:\n",
      "            distances = []\n",
      "        finally:\n",
      "            return distances\n",
      "\n",
      "def check_accuracy(data, xa_column_name, xb_column_name):\n",
      "    \"\"\"\n",
      "    Checks the accuracy of two columns in the same dataframe and returns the percent that are the same.\n",
      "    \n",
      "    data - pandas dataframe\n",
      "    xa_column_name - first column to be compared\n",
      "    xb_column_name - second column to be compared\n",
      "    \"\"\"\n",
      "    num_of_same = len(data[data[xa_column_name] == data[xb_column_name]])\n",
      "    num_total = len(data)\n",
      "    output = (num_of_same/num_total)*100\n",
      "    return output\n",
      "\n",
      "def drop_and_split(data,column_to_drop = \"\"):\n",
      "    \"\"\"\n",
      "    Drops the column indicated in the 'column_to_drop' parameter and splits the data set into train and test datasets.\n",
      "    \n",
      "    Uses 20% of the data for the test dataset\n",
      "    \n",
      "    Returns train,test as pandas dataframes\n",
      "    \n",
      "    data - pandas dataframe\n",
      "    column_to_drop - the name of the column to drop from the dataset(string)\n",
      "    \"\"\"\n",
      "    #one_drop = data.drop(column_to_drop,1)\n",
      "    #column_names = list(one_drop.columns.values)\n",
      "    train, test = train_test_split(data, test_size=0.20, random_state = 24)\n",
      "    train = pd.DataFrame(train,columns=data.columns.values.tolist())\n",
      "    test = pd.DataFrame(test,columns=data.columns.values.tolist())\n",
      "    return train,test\n",
      "\n",
      "        \n",
      "def create_input_file(method, stat_matching_dict,donor_data, donor_abbreviation, donor_columns, client_final, client_abbreviation):\n",
      "    #convert distances to a dataframe and add IDs as indices\n",
      "    distancesDF = pd.DataFrame(stat_matching_dict, index=pd.np.array(client_final[[client_abbreviation + '_ID']][client_abbreviation + '_ID']))\n",
      "    distancesDF.columns = pd.np.array(donor_final[[donor_abbreviation + '_ID']][donor_abbreviation + '_ID'])\n",
      "\n",
      "    matched_records = distancesDF.idxmin(axis=1).to_dict()\n",
      "    #print method + \": IDs indexed...\" + str(datetime.now())\n",
      "    \n",
      "    donor_input = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "    donor_input.describe()\n",
      "    #print method + \": Donor Input created...\" + str(datetime.now())\n",
      "    \n",
      "    #assemble input file fields from client and donor datasets based on matched IDs\n",
      "    input_file_list = []\n",
      "\n",
      "    for client_id, donor_id in matched_records.iteritems():\n",
      "        matched_record = donor_input[donor_input[donor_abbreviation + '_ID'] == donor_id]\n",
      "        matched_record[client_abbreviation + '_ID'] = client_id\n",
      "        input_file_list.append(matched_record)\n",
      "        \n",
      "    #print method + \": matched records found and created...\" + str(datetime.now())\n",
      "\n",
      "    input_file = pd.concat(input_file_list)\n",
      "    #print method + \": input file concatenated...\" + str(datetime.now())\n",
      "\n",
      "    #merge the donor data with the client data for comparison\n",
      "    input_file = pd.merge(input_file, client_final, how = 'left', left_on=client_abbreviation + '_ID', right_on=client_abbreviation + '_ID')\n",
      "    #print method + \": input file merged...\" + str(datetime.now())\n",
      "    \n",
      "    input_file.to_csv(\"../../../../data/synthetic_population/outputs/\" + method + \".csv\")\n",
      "    #print method + \": input file saved...\" + str(datetime.now())\n",
      "    print method, \"is complete\", str(datetime.now())\n",
      "\n",
      "    \n",
      "def ml_matching(client,donor,p_type,dependent,independent,donor_abbreviation,client_abbreviation):    \n",
      "    acc_dict = {}\n",
      "    \n",
      "    donor_dep = []\n",
      "    donor_ind = ''\n",
      "    client_dep = []\n",
      "    client_ind = ''\n",
      "\n",
      "    for col in donor.columns.values:\n",
      "        for dep in dependent:\n",
      "            if dep in col:\n",
      "                donor_dep.append(col)\n",
      "        if independent in col:\n",
      "            donor_ind = col\n",
      "    \n",
      "    for col in client.columns.values:\n",
      "        for dep in dependent:\n",
      "            if dep in col:\n",
      "                client_dep.append(col)\n",
      "        if independent in col:\n",
      "            client_ind = col\n",
      "\n",
      "    #for col in train.columns.values:\n",
      "    #    if col.find(donor_ind) < 0 and col.find(\"ID\") < 0:\n",
      "    #        donor_dep.append(col)\n",
      "    #    elif col.find(y_v) > -1 and col.find(donor_abbreviation) > -1:\n",
      "    #        donor_ind = col\n",
      "    #for col in XA.columns.values:\n",
      "    #    if col.find(y_v) < 0 and col.find(\"ID\") < 0:\n",
      "    #        x_vars.append(col)\n",
      "    #    elif col.find(y_v) > -1 and col.find(client_abbreviation) > -1:\n",
      "    #        y_var = col\n",
      "\n",
      "    d_train, d_test = drop_and_split(donor)\n",
      "    \n",
      "    if p_type == 'r':\n",
      "        #SVM\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf = SVR()\n",
      "        clf.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_SVM'\n",
      "        d_train_x[d_new_col_name] = clf.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_SVM'\n",
      "        c_x[c_new_col_name] = clf.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['SVM'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        #KNN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf2 = KNeighborsRegressor()\n",
      "        clf2.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_KNN'\n",
      "        d_train_x[d_new_col_name] = clf2.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf2.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_KNN'\n",
      "        c_x[c_new_col_name] = clf2.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['KNN'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        #LIN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "\n",
      "        clf3 = LinearRegression()\n",
      "        clf3.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_LIN'\n",
      "        d_train_x[d_new_col_name] = clf3.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf3.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_LIN'\n",
      "        c_x[c_new_col_name] = clf3.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['LIN'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        #Decision Tree    \n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf4 = DecisionTreeRegressor()\n",
      "        clf4.fit(d_train_x,d_train_y)\n",
      "\n",
      "        d_new_col_name = donor_ind + '_PREDICT_DT'\n",
      "        d_train_x[d_new_col_name] = clf4.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf4.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_DT'\n",
      "        c_x[c_new_col_name] = clf4.predict(c_x)\n",
      "        \n",
      "        client_acc = mean_squared_error(list(c_y),list(c_x[c_new_col_name]))\n",
      "        train_acc = mean_squared_error(list(d_train_y),list(d_train_x[d_new_col_name]))\n",
      "        test_acc = mean_squared_error(list(d_test_y),list(d_test_x[d_new_col_name]))\n",
      "        \n",
      "        acc_dict['DT'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        return acc_dict\n",
      "    \n",
      "    elif p_type == 'c':\n",
      "        #SVM\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "    \n",
      "        clf = SVC()\n",
      "        clf.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_SVM'\n",
      "        d_train_x[d_new_col_name] = clf.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_SVM'\n",
      "        c_x[c_new_col_name] = clf.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['SVM']= client_acc, train_acc, test_acc\n",
      "        #accuracy_score(list(test[y_var]),list(test[new_col_name]))*100\n",
      "        \n",
      "        #KNN\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf2 = KNeighborsClassifier()\n",
      "        clf2.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_KNN'\n",
      "        d_train_x[d_new_col_name] = clf2.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf2.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_KNN'\n",
      "        c_x[c_new_col_name] = clf2.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['KNN'] = client_acc, train_acc, test_acc\n",
      "\n",
      "\n",
      "        #Log Reg\n",
      "        d_train_x = d_train[donor_dep]\n",
      "        d_train_y = d_train[donor_ind]\n",
      "        d_test_x = d_test[donor_dep]\n",
      "        d_test_y = d_test[donor_ind]\n",
      "        c_x = client[client_dep]\n",
      "        c_y = client[client_ind]\n",
      "        \n",
      "        clf3 = LogisticRegression()\n",
      "        clf3.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_LOG'\n",
      "        d_train_x[d_new_col_name] = clf3.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf3.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_LOG'\n",
      "        c_x[c_new_col_name] = clf3.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['LOG'] = client_acc, train_acc, test_acc\n",
      "\n",
      "        #Decision Tree\n",
      "        clf4 = DecisionTreeClassifier()\n",
      "        clf4.fit(d_train_x,d_train_y)\n",
      "        \n",
      "        d_new_col_name = donor_ind + '_PREDICT_DT'\n",
      "        d_train_x[d_new_col_name] = clf4.predict(d_train_x)\n",
      "        d_test_x[d_new_col_name] = clf4.predict(d_test_x)\n",
      "\n",
      "        c_new_col_name = client_ind + '_PREDICT_DT'\n",
      "        c_x[c_new_col_name] = clf4.predict(c_x)\n",
      "        \n",
      "        client_acc = accuracy_score(list(c_y),c_x[c_new_col_name])\n",
      "        train_acc = accuracy_score(list(d_train_y),d_train_x[d_new_col_name])\n",
      "        test_acc = accuracy_score(list(d_test_y),d_test_x[d_new_col_name])\n",
      "        \n",
      "        acc_dict['DT'] = client_acc, train_acc, test_acc\n",
      "        \n",
      "        return acc_dict\n",
      "    else:\n",
      "        print \"the prediction type must be a regression or a classifier\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import the client data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Change the client abbreviation variable to an identifiable abbreviation you'd like to add to the front of your column names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#client abbreviation that will be used throughout the script\n",
      "client_abbreviation = 'PUMD'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Select the columns you'd like to match in the key of the dictionary and rename it in the value of the dictionary. (e.g. {'random_variable_name':'meaningful_variable_name'})\n",
      "\n",
      "Do not worry about adding dataset indicators in the variable names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#identify the columns we're interested in - change the varaible names here\n",
      "client_columns = {'NEWID':'ID','SEX_REF':'SEX','AGE_REF':'AGE','FSALARYX':'SALARY','STATE':'STATE_CODE',\n",
      "                  'CUTENURE':'ORIG_HOUSE_STATUS'}\n",
      "#import the client dataset - if the dataset is large, this may take minutes to finish\n",
      "client_data = import_data(\"../../../../data/synthetic_population/Interview_2013_FMLI_all.xlsx\")\n",
      "#grab the columns we're interested in and change the column names to more meaningful descriptors\n",
      "client_filtered = matching_columns(client_data,client_abbreviation,client_columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Transform the client data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#map values to different values to be consistent across datasets\n",
      "client_filtered[client_abbreviation + '_' + 'NEW_HOME_STATUS'] = client_filtered[client_abbreviation + '_' + 'ORIG_HOUSE_STATUS'].map({1:1,2:1,3:1,4:2,5:3,6:3})\n",
      "\n",
      "#import state code data\n",
      "state_codes = import_data('../../../../data/synthetic_population/State Codes.csv')\n",
      "\n",
      "#create a dictionary with this structure {'State Code':'State Abbreviation'}\n",
      "state_code_dict = dict(zip(state_codes.Code, state_codes.Abb))\n",
      "\n",
      "#transform the state codes into state abbreviations based on our state code data\n",
      "client_filtered[client_abbreviation + '_' + 'STATE_ABB'] = client_filtered[client_abbreviation + '_' + 'STATE_CODE'].map(state_code_dict)\n",
      "\n",
      "#drop the original columns that were transformed\n",
      "client_final = client_filtered.drop([client_abbreviation + '_' + 'STATE_CODE',\n",
      "                                     client_abbreviation + '_' + 'ORIG_HOUSE_STATUS'],1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import the donor data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#donor abbreviation that will be used throughout the script\n",
      "donor_abbreviation = \"SBI\"\n",
      "\n",
      "#identify the columns we're interested in - change the varaible names here\n",
      "donor_columns = {'ID':'ID','OCALC_4':'AGE','OCALC_27':'SALARY','OCALC_10':'SEX','STATE':'STATE','G4':'HOME_STATUS'}\n",
      "\n",
      "#pull in donor dataset\n",
      "donor_data = import_data('../../../../data/synthetic_population/SBI_Complete.csv')\n",
      "\n",
      "#filter for the columns that we're interested in - this also renameds the columns\n",
      "donor_filtered = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "donor_final = donor_filtered"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Start Here - Stat Match"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#choose number of client records to match and pull an array of that many records at random\n",
      "n = 5000\n",
      "client_final = client_final.ix[random.sample(client_final.index,n)]\n",
      "len(client_final)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "5000"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create matrix of distance measurements\n",
      "XA = client_final[['PUMD_AGE','PUMD_SEX']]#,'PUMD_NEW_HOME_STATUS']]#,'PUMD_SALARY']]\n",
      "#[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "XB = donor_final[['SBI_AGE','SBI_SEX']]#,'SBI_HOME_STATUS']]#,'SBI_SALARY']]\n",
      "#[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a dictionary with the statistical matching method as the key and the matching array as the value\n",
      "stat_matching_dict = {}\n",
      "potential_methods = [\"braycurtis\",\"cityblock\",\"correlation\",\"cosine\",\"euclidean\",\"minkowski\",\"sqeuclidean\"]\n",
      "for method in potential_methods:\n",
      "    output = get_distances(XA,XB,method)\n",
      "    stat_matching_dict[method] = output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for method in potential_methods:\n",
      "    print \"Method - \" + method, \"started...\" + str(datetime.now())\n",
      "    create_input_file(method,stat_matching_dict[method],donor_data, donor_abbreviation, donor_columns, client_final, client_abbreviation)\n",
      "    print \"Method - \" + method, \"complete...\" + str(datetime.now())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Method - braycurtis started...2015-02-04 12:12:58.357104\n",
        "braycurtis"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:03.313493\n",
        "Method - braycurtis"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:03.394669\n",
        "Method - cityblock started...2015-02-04 12:13:03.394699\n",
        "cityblock"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:08.274962\n",
        "Method - cityblock"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:08.350936\n",
        "Method - correlation started...2015-02-04 12:13:08.350982\n",
        "correlation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:13.283244\n",
        "Method - correlation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:13.358351\n",
        "Method - cosine started...2015-02-04 12:13:13.358380\n",
        "cosine"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:18.179131\n",
        "Method - cosine"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:18.269489\n",
        "Method - euclidean started...2015-02-04 12:13:18.269530\n",
        "euclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:23.105687\n",
        "Method - euclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:23.195972\n",
        "Method - minkowski started...2015-02-04 12:13:23.196002\n",
        "minkowski"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:28.056689\n",
        "Method - minkowski"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:28.147991\n",
        "Method - sqeuclidean started...2015-02-04 12:13:28.148031\n",
        "sqeuclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is complete 2015-02-04 12:13:33.077052\n",
        "Method - sqeuclidean"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complete...2015-02-04 12:13:33.156234\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc_score = {'rows': '5000','vars':2,'data':{}}\n",
      "variables = ['SEX','HOME','AGE','SALARY']\n",
      "for method in potential_methods:\n",
      "    temp_dict = {}\n",
      "    temp_df = pd.DataFrame.from_csv('../../../../data/synthetic_population/outputs/' + method + '.csv')\n",
      "    for var in variables:\n",
      "        c_col = \"\"\n",
      "        d_col = \"\"\n",
      "        for col in temp_df.columns.values:\n",
      "                if var in col and client_abbreviation in col:\n",
      "                    c_col = col\n",
      "                elif var in col and donor_abbreviation in col:\n",
      "                    d_col = col\n",
      "        if var in ['SEX','HOME']:\n",
      "            temp_dict[var] = accuracy_score(temp_df[c_col],temp_df[d_col])\n",
      "        elif var in ['SALARY', 'AGE']:\n",
      "            temp_dict[var] = mean_squared_error(temp_df[c_col],temp_df[d_col])\n",
      "        else:\n",
      "            temp_dict[var] = 'error'\n",
      "\n",
      "    acc_score['data'][method] = temp_dict\n",
      "\n",
      "with open(\"../../../../data/synthetic_population/outputs/matching_ml_output.json\", 'w') as f:\n",
      "    json.dump(acc_score, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Start Here - ML Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#choose number of client records to match and pull an array of that many records at random\n",
      "n = 5000\n",
      "client_final = client_final.ix[random.sample(client_final.index,n)]\n",
      "len(client_final)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": [
        "5000"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create matrix of distance measurements\n",
      "XA = client_final[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "#[['PUMD_AGE','PUMD_SEX','PUMD_NEW_HOME_STATUS','PUMD_SALARY']]\n",
      "XB = donor_final[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]\n",
      "#[['SBI_AGE','SBI_SEX','SBI_HOME_STATUS','SBI_SALARY']]\n",
      "\n",
      "# replace NaNs\n",
      "XB['SBI_HOME_STATUS'] = pd.np.where(XB['SBI_HOME_STATUS'].isnull(),0,XB['SBI_HOME_STATUS'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "variables = ['SALARY','SEX','HOME','AGE']\n",
      "accuracy_dict = {'rows':str(n),'vars':3,'data':{}}\n",
      "for var in variables:\n",
      "    dep = ['SALARY','SEX','HOME','AGE']\n",
      "    dep.remove(var)\n",
      "    ind = var\n",
      "    if ind in ['AGE','SALARY']:\n",
      "        p_type = 'r'\n",
      "    elif ind in ['SEX','HOME']:\n",
      "        p_type = 'c'\n",
      "    accuracy_dict['data'][var] = ml_matching(XA,XB,p_type,dep,ind,donor_abbreviation,client_abbreviation)\n",
      "\n",
      "with open(\"../../../../data/synthetic_population/outputs/matching_ml_output.json\", 'w') as f:\n",
      "    json.dump(accuracy_dict, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Overflow"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ORIGINAL\n",
      "#select statistical matching method to use\n",
      "#potential_methods = [\"braycurtis\",\"cityblock\",\"correlation\",\"cosine\",\"euclidean\",\"minkowski\",\"sqeuclidean\"]\n",
      "variables = ['SEX', 'AGE'] #HOME SALARY\n",
      "output_dict = {}\n",
      "for method in potential_methods:\n",
      "    print method, \"has started...\"\n",
      "    match_file = pd.read_csv('../../../data/synthetic_population/outputs/' + method + '.csv')\n",
      "    match_file = match_file.drop('Unnamed: 0',1)\n",
      "    donor_input = matching_columns(donor_data,donor_abbreviation,donor_columns)\n",
      "    temp_dict = {}\n",
      "    for var in variables:\n",
      "        print var, \"has started...\"\n",
      "        if var in ['SEX','HOME']:\n",
      "            this_type = 'c'\n",
      "        elif var in ['AGE','SALARY']:\n",
      "            this_type = 'r'\n",
      "        else:\n",
      "            print \"WTF\"\n",
      "        try:\n",
      "            temp_dict[var] = predict(match_file,this_type,client_abbreviation,var)\n",
      "        except:\n",
      "            temp_dict[var] = \"Error\"\n",
      "            continue\n",
      "        print var, \"has completed...\"      \n",
      "    output_dict[method] = temp_dict\n",
      "    print method, \"has completed...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}